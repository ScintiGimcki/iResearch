{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 爱科研-人工智能科研实训\n",
    "## 毕业项目 - 使用卷积神经网络破解验证码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "本项目会通过 Keras 搭建一个深度卷积神经网络来识别 captcha 验证码，建议使用显卡来运行该项目，Keras 版本：2.1.0。\n",
    "\n",
    "下面的可视化代码都是在 jupyter notebook 中完成的，如果你希望写成 python 脚本，稍加修改即可正常运行，当然也可以去掉这些可视化代码。\n",
    "\n",
    "### 效果预览\n",
    "\n",
    "![](./images/preview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 验证码库 Captcha\n",
    "\n",
    "captcha 是用 python 写的生成验证码的库，它支持图片验证码和语音验证码，我们使用的是它生成图片验证码的功能。首次使用需使用下面的命令进行安装\n",
    "```\n",
    "pip install captcha\n",
    "```\n",
    "\n",
    "首先我们设置我们的验证码格式为数字加大写字母："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from captcha.image import ImageCaptcha\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import string\n",
    "characters = string.digits + string.ascii_uppercase\n",
    "print('The security codes are composed by:\\n{}'.format(characters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "设置长宽以及字符数，生成一串验证码试试看："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "width, height, n_len, n_class = 170, 80, 4, len(characters)+1\n",
    "\n",
    "generator = ImageCaptcha(width=width, height=height)\n",
    "random_str = ''.join([random.choice(characters) for j in range(4)])\n",
    "img = generator.generate_image(random_str)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.title(random_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 构建深度卷积神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 损失函数 - CTC Loss\n",
    "\n",
    "CTC Loss可以在只知道序列的顺序，不知道具体位置的情况下，让模型收敛，因此非常适合于验证码识别的场景。（[warp-ctc](https://github.com/baidu-research/warp-ctc)）\n",
    "\n",
    "![](./images/ctc2.jpg)\n",
    "\n",
    "那么在 Keras 里面，CTC Loss 已经内置了，我们直接定义这样一个函数即可，由于我们采用循环神经网络处理卷积神经网络导出的特征向量，所以默认丢掉前面两个输出，因为它们通常无意义，且会影响模型的输出。\n",
    "\n",
    "* y\\_pred 是模型的输出，是按顺序输出的37个字符的概率，因为我们这里用到了循环神经网络，所以需要一个空白字符的类；\n",
    "* labels 是验证码，是四个数字，每个数字对应字符的编号；\n",
    "* input\\_length 表示 y\\_pred 的长度，我们这里是15；\n",
    "* label\\_length 表示 labels 的长度，我们这里是4。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 模型结构\n",
    "\n",
    "我们的模型结构是这样设计的，首先通过卷积神经网络去识别特征，然后经过一个全连接降维，再按水平顺序输入到一种特殊的循环神经网络，叫 GRU，全程是 Gated Recurrent Unit，可以理解为是 LSTM 的简化版。LSTM 早在1997年就已经被发明出来了，但是 GRU 直到2014年才出现。经过实验，GRU 效果比 LSTM 要好。\n",
    "\n",
    "参考链接：https://zhuanlan.zhihu.com/p/28297161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "rnn_size = 128\n",
    "\n",
    "input_tensor = Input((width, height, 3))\n",
    "x = input_tensor\n",
    "x = Lambda(lambda x:(x-127.5)/127.5)(x)\n",
    "for i in range(3):\n",
    "    for j in range(2):\n",
    "        x = Convolution2D(32*2**i, 3, kernel_initializer='he_uniform')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "conv_shape = x.get_shape().as_list()\n",
    "rnn_length = conv_shape[1]\n",
    "rnn_dimen = conv_shape[2]*conv_shape[3]\n",
    "print(conv_shape, rnn_length, rnn_dimen)\n",
    "x = Reshape(target_shape=(rnn_length, rnn_dimen))(x)\n",
    "rnn_length -= 2\n",
    "\n",
    "x = Dense(rnn_size, kernel_initializer='he_uniform')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "gru_1 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_uniform', name='gru1')(x)\n",
    "gru_1b = GRU(rnn_size, return_sequences=True, kernel_initializer='he_uniform', \n",
    "             go_backwards=True, name='gru1_b')(x)\n",
    "x = add([gru_1, gru_1b])\n",
    "\n",
    "gru_2 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_uniform', name='gru2')(x)\n",
    "gru_2b = GRU(rnn_size, return_sequences=True, kernel_initializer='he_uniform', \n",
    "             go_backwards=True, name='gru2_b')(x)\n",
    "x = concatenate([gru_2, gru_2b])\n",
    "\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(n_class, activation='softmax')(x)\n",
    "base_model = Model(inputs=input_tensor, outputs=x)\n",
    "\n",
    "labels = Input(name='the_labels', shape=[n_len], dtype='float32')\n",
    "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), \n",
    "                  name='ctc')([x, labels, input_length, label_length])\n",
    "\n",
    "model = Model(inputs=[input_tensor, labels, input_length, label_length], outputs=[loss_out])\n",
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "从 Input 到 最后一个 MaxPooling2D，是一个很深的卷积神经网络，它负责学习字符的各个特征，尽可能区分不同的字符。它输出 shape 是 `[None, 17, 6, 128]`，这个形状相当于把一张宽为 170，高为 80 的彩色图像 (170, 80, 3)，压缩为宽为 17，高为 6 的 128维特征的特征图 (17, 6, 128)。\n",
    "\n",
    "然后我们把图像 reshape 成 (17, 768)，也就是把高和特征放在一个维度，然后降维成 (17, 128)，也就是从左到右有17条特征，每个特征128个维度。\n",
    "\n",
    "这128个维度就是这一条图像的非常高维，非常抽象的概括，然后我们将17个特征向量依次输入到 GRU 中，GRU 有能力学会不同特征向量的组合会代表什么字符，即使是字符之间有粘连也不会怕。这里使用了双向 GRU，\n",
    "\n",
    "最后 Dropout 接一个全连接层，作为分类器输出每个字符的概率。\n",
    "\n",
    "这个是 base\\_model 的结构，也是我们模型的结构。那么后面的 labels, input\\_length, label\\_length 和 loss_out 都是为了输入必要的数据来计算 CTC Loss 的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 模型可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "[图片链接](http://www.zihanhuang.com/projects/images/model.png)\n",
    "\n",
    "可以看到模型非常复杂，但实际上只是因为输入比较多，所以它显得很大。还有一个值得注意的地方，我们的图片在输入的时候是经过了旋转的，这是因为我们希望以水平方向输入循环神经网络，而图片在 numpy 里默认是这样的形状：(height, width, 3)，因此我们使用了 `transpose` 函数将图片转为了(width, height, 3)的格式，这样就能把 X 轴转到第一个维度，方便输入到循环神经网络。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 数据生成器\n",
    "\n",
    "训练模型的时候，我们可以选择两种方式来生成我们的训练数据，一种是一次性生成几万张图，然后开始训练，一种是定义一个数据生成器，然后利用 fit_generator 函数来训练。\n",
    "\n",
    "第一种方式的好处是训练的时候显卡利用率高，如果你需要经常调参，可以一次生成，多次使用；第二种方式的好处是你不需要生成大量数据，训练过程中可以利用 CPU 生成数据，而且还有一个好处是你可以无限生成数据。\n",
    "\n",
    "根据神经网络模型的输入，我们需要输入四个数据：\n",
    "\n",
    "* X 是一批图片；\n",
    "* y 是每个图片对应的 label，最大长度为 n_len；\n",
    "* input\\_length 表示模型输出的长度，我们这里是15；\n",
    "* label\\_length 表示 labels 的长度，我们这里是4。\n",
    "\n",
    "最后还有一个输入是 `np.ones(batch_size)`，这是因为 Keras 在训练模型的时候必须输入一个 X 和一个 y，我们这里把上面四个都合并为一个 X 了，因此实际上 y 没有参与 loss 的计算，所以随便编一个 `batch_size` 长度的数据输入进去就好了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen(batch_size=128):\n",
    "    X = np.zeros((batch_size, width, height, 3), dtype=np.uint8)\n",
    "    y = np.zeros((batch_size, n_len), dtype=np.uint8)\n",
    "    generator = ImageCaptcha(width=width, height=height)\n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            random_str = ''.join([random.choice(characters) for j in range(n_len)])\n",
    "            X[i] = np.array(generator.generate_image(random_str)).transpose(1, 0, 2)\n",
    "            y[i] = [characters.find(x) for x in random_str]\n",
    "        yield [X, y, np.ones(batch_size)*rnn_length, np.ones(batch_size)*n_len], np.ones(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "我们可以举个例子，使用一次生成器，看看输出的是什么内容："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_vis, y_vis, input_length_vis, label_length_vis), _ = next(gen(1))\n",
    "print(X_vis.shape, y_vis, input_length_vis, label_length_vis)\n",
    "\n",
    "plt.imshow(X_vis[0].transpose(1, 0, 2))\n",
    "plt.title(''.join([characters[i] for i in y_vis[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "我们可以看到输出了下面的内容：\n",
    "\n",
    "`(1, 170, 80, 3) [[11 27  8 29]] [ 15.] [ 4.]`\n",
    "\n",
    "这里：\n",
    "\n",
    "* X 的 shape 是 `(1, 170, 80, 3)`，如果有 n 张图，shape 就是 `(n, 170, 80, 3)`\n",
    "* y 是 label，我们可以看到生成的图片是 T4LL，那么按上面的 characters，label 就是 `[29 4 21 21]`，外面还有一个框是因为这里面可以有 n 个 label\n",
    "* input\\_length 表示模型输出的长度，我们这里是15；\n",
    "* label\\_length 表示 labels 的长度，我们这里是4。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 评估模型\n",
    "\n",
    "### 评估函数\n",
    "我们会通过这个函数来评估我们的模型，和上面的评估标准一样，只有全部正确，我们才算预测正确。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(batch_size=128, steps=10):\n",
    "    batch_acc = 0\n",
    "    generator = gen(batch_size)\n",
    "    for i in range(steps):\n",
    "        [X_test, y_test, _, _], _  = next(generator)\n",
    "        y_pred = base_model.predict(X_test)\n",
    "        shape = y_pred[:,2:,:].shape\n",
    "        ctc_decode = K.ctc_decode(y_pred[:,2:,:], input_length=np.ones(shape[0])*shape[1])[0][0]\n",
    "        out = K.get_value(ctc_decode)[:, :n_len]\n",
    "        if out.shape[1] == n_len:\n",
    "            batch_acc += (y_test == out).all(axis=1).mean()\n",
    "    return batch_acc / steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 评估回调\n",
    "\n",
    "因为 Keras 没有针对 CTC 模型计算准确率的选项，因此我们需要自定义一个回调函数，它会在每一代训练完成的时候计算模型的准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import *\n",
    "\n",
    "class Evaluator(Callback):\n",
    "    def __init__(self):\n",
    "        self.accs = []\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        acc = evaluate(steps=20)*100\n",
    "        self.accs.append(acc)\n",
    "        print('')\n",
    "        print('acc: %f%%' % acc)\n",
    "\n",
    "evaluator = Evaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 训练模型\n",
    "\n",
    "我们先按 `Adam(1e-3)` 的学习率训练20代，让模型快速收敛，然后以 `Adam(1e-4)` 的学习率再训练20代。这里设置每代训练 400 个 step，也就是每代 `400*128=51200` 个样本，验证集设置的是 `20*128=2048` 个样本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = model.fit_generator(gen(128), steps_per_epoch=400, epochs=20,\n",
    "                        callbacks=[evaluator],\n",
    "                        validation_data=gen(128), validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=Adam(1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h2 = model.fit_generator(gen(128), steps_per_epoch=400, epochs=20, \n",
    "                        callbacks=[evaluator],\n",
    "                        validation_data=gen(128), validation_steps=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "然后我们将损失函数 loss 和准确度 acc 的曲线图画出来："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with mpl.rc_context(rc={'font.family': 'serif', 'font.size': 11}):\n",
    "    fig = plt.figure(figsize=(12,4))\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    plt.plot(h.history['loss'] + h2.history['loss'])\n",
    "    plt.plot(h.history['val_loss'] + h2.history['val_loss'])\n",
    "    plt.legend(['train', 'val'], loc='upper right')\n",
    "    plt.ylim(0,1)\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    plt.plot(evaluator.accs)\n",
    "    plt.ylim(80,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 载入权值\n",
    "\n",
    "由于训练神经网络运算量过大，可以载入之前已经训练好的模型进行效果预览。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('iResearch-model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 测试模型\n",
    "\n",
    "我们可以尝试计算模型的总体准确率，以及看看模型到底错在哪。首先生成10000个样本，然后用 `base_model` 进行预测，然后裁剪并进行 ctc 解码，最后裁剪到4个 label 并与真实值进行对比。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_vis, y_vis, input_length_vis, label_length_vis), _ = next(gen(10000))\n",
    "\n",
    "y_pred = base_model.predict(X_vis, verbose=1)\n",
    "shape = y_pred[:,2:,:].shape\n",
    "ctc_decode = K.ctc_decode(y_pred[:,2:,:], input_length=np.ones(shape[0])*shape[1])[0][0]\n",
    "out = K.get_value(ctc_decode)[:, :4]\n",
    "\n",
    "(y_vis == out).all(axis=1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "我们可以对预测错的样本进行统计。我们可以发现模型在 0 和 O 的准确率稍微低一点，其他的错误都只是个例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(''.join([characters[i] for i in y_vis[y_vis != out]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 效果预览"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_vis, y_vis, input_length_vis, label_length_vis), _ = next(gen(12))\n",
    "\n",
    "y_pred = base_model.predict(X_vis)\n",
    "shape = y_pred[:,2:,:].shape\n",
    "ctc_decode = K.ctc_decode(y_pred[:,2:,:], input_length=np.ones(shape[0])*shape[1])[0][0]\n",
    "out = K.get_value(ctc_decode)[:, :4]\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "for i in range(12):\n",
    "    plt.subplot(3, 4, i+1)\n",
    "    plt.imshow(X_vis[i].transpose(1, 0, 2))\n",
    "    plt.title('pred:%s\\nreal :%s' % (''.join([characters[x] for x in out[i]]), \n",
    "                                     ''.join([characters[x] for x in y_vis[i]])))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:iResearch]",
   "language": "python",
   "name": "conda-env-iResearch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
